HCLTech Case Study 1 - IT Operations Automation
https://img.shields.io/badge/Python-3.8+-blue.svg
https://img.shields.io/badge/Flask-2.3+-green.svg
https://img.shields.io/badge/Pandas-2.0+-orange.svg
https://img.shields.io/badge/License-MIT-yellow.svg

A comprehensive Python-based log file analyzer designed for HCLTech's large-scale IT infrastructure. Processes server log files to generate actionable insights for system administrators with web interface support.

https://static/preview.png

ğŸ¯ Features
ğŸ“ˆ High Performance: Processes 50,000+ log entries in under 3 seconds

ğŸ–¥ï¸ Web Interface: Modern, responsive dashboard with real-time analysis

ğŸ“Š Interactive Visualizations: Error distribution charts and IP analysis

ğŸ“‹ Comprehensive Reports: Detailed analysis with actionable insights

ğŸ›¡ï¸ Robust Error Handling: Gracefully processes malformed log entries

ğŸ“ Audit Logging: Complete execution tracking and debugging

ğŸ“ File Upload: Support for custom log files up to 100MB

ğŸš€ Performance Metrics
Metric	Result
Processing Speed	18,627 lines/second
Large File Support	â‰¥50,000 lines
Success Rate	97.97% parsing accuracy
Memory Efficiency	Line-by-line processing
Error Handling	1,017+ malformed entries handled





ğŸ—ï¸ Project Structure
text
log_analyzer/
â”œâ”€â”€ data/                    # Log files
â”‚   â”œâ”€â”€ server_logs.txt              # Sample data (16 lines)
â”‚   â””â”€â”€ large_server_logs.txt        # Test data (50,000+ lines)
â”‚
â”œâ”€â”€ src/                     # Core analyzer modules
â”‚   â”œâ”€â”€ config.py                   # Configuration settings
â”‚   â”œâ”€â”€ log_reader.py              # File reading and validation
â”‚   â”œâ”€â”€ log_parser.py              # Regex parsing and extraction
â”‚   â”œâ”€â”€ data_processor.py          # Pandas data analysis
â”‚   â”œâ”€â”€ visualizer.py              # Matplotlib charts
â”‚   â”œâ”€â”€ report_generator.py        # Text report generation
â”‚   â”œâ”€â”€ main.py                    # CLI entry point
â”‚   â””â”€â”€ __init__.py                # Package initialization
â”‚
â”œâ”€â”€ static/                  # Web assets
â”‚   â”œâ”€â”€ style.css                  # CSS styles
â”‚   â””â”€â”€ script.js                  # JavaScript functionality
â”‚
â”œâ”€â”€ templates/               # HTML templates
â”‚   â””â”€â”€ index.html                # Main dashboard
â”‚
â”œâ”€â”€ uploads/                 # User uploaded files
â”œâ”€â”€ output/                  # Generated reports and charts
â”œâ”€â”€ logs/                    # Execution logs
â”œâ”€â”€ tests/                   # Unit tests
â”‚
â”œâ”€â”€ app.py                   # Flask web application
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ generate_large_logs.py   # Test data generator
â””â”€â”€ README.md               # This file
ğŸ“‹ Prerequisites
Python 3.8 or higher

pip (Python package manager)

ğŸ”§ Installation
1. Clone/Download the Project
bash
# Download the project to your computer
# Extract to: C:\projects\log_analyzer
2. Create Virtual Environment (Recommended)
bash
cd C:\projects\log_analyzer
python -m venv venv

# Activate virtual environment:
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate
3. Install Dependencies
bash
pip install -r requirements.txt
4. Generate Test Data (Optional)
bash
python generate_large_logs.py
This creates a 50,000-line test file at data/large_server_logs.txt

ğŸš€ Usage
Option 1: Web Interface (Recommended)
bash
# Start the web application
python app.py

# Open browser and navigate to:
# http://localhost:5000
Web Interface Features:

ğŸ“ Upload custom log files

âš¡ One-click analysis of 50,000+ line sample

ğŸ“Š Interactive charts and visualizations

ğŸ“¥ Downloadable reports

ğŸ“± Responsive design for all devices

Option 2: Command Line Interface
bash
cd src
python main.py
Command Line Output Includes:

File statistics and parsing results

Error code distribution

Top 5 error-generating IP addresses

Summary report generation

Chart creation

ğŸ“ Log File Format
The analyzer expects log files in this specific format:

Required Format (CSV-style)
text
TIMESTAMP, IP_ADDRESS, REQUEST_TYPE, HTTP_STATUS_CODE
Example Valid Entries
text
2025-01-15 10:32:45,192.168.1.10,GET,404
2025-01-15 10:32:46,192.168.1.12,POST,500
2025-01-15 10:32:47,192.168.1.15,GET,200
2025-01-15 10:32:48,192.168.1.16,PUT,403
Field Specifications
Field	Format	Valid Values
Timestamp	YYYY-MM-DD HH:MM:SS	Valid date/time
IP Address	IPv4 format	192.168.1.1 to 192.168.255.255
Request Type	HTTP Methods	GET, POST, PUT, DELETE, HEAD, OPTIONS, PATCH
HTTP Code	3-digit number	200, 404, 500, 403, etc.
ğŸ“Š Expected Output
1. Console/Web Dashboard
text
LOG FILE ANALYZER
============================================================

ğŸ“‚ File Statistics:
   Total Lines: 50,000
   Successfully Parsed: 48,983 (97.97%)
   Failed to Parse: 1,017

ğŸ“ˆ Analysis Results:
   Total Requests: 48,983
   Error Requests: 24,491 (50.00%)
   Success Requests: 24,492
   Unique IPs: 100
   Unique Error IPs: 80

ğŸ”´ Error Code Distribution:
   HTTP 404: 6,000 errors
   HTTP 500: 6,000 errors
   HTTP 403: 4,500 errors

ğŸŒ Top Error IPs:
   192.168.23.45: 800 errors
   192.168.67.89: 750 errors
   192.168.12.34: 700 errors

âš¡ Performance:
   Processing Time: 2.68 seconds
   Speed: 18,627 lines/second
2. Generated Files
output/summary_report.txt - Complete text analysis

output/error_distribution.png - Error code bar chart

output/top_ips.png - Top IP addresses chart

logs/execution.log - Detailed execution timeline

âœ… Case Study Requirements Met
Requirement	Status	Proof
Process â‰¥50,000 log files	âœ… Met	Tested with 50,000 lines
Identify and count HTTP error codes	âœ… Met	Error distribution analysis
Find top 5 IP addresses with errors	âœ… Met	Top IP identification
Generate summary reports	âœ… Met	Report generation
Create visualizations	âœ… Met	Chart generation
Handle invalid/corrupted entries	âœ… Met	1,017 malformed entries handled
Log program execution	âœ… Met	execution.log created
Modular design	âœ… Met	Separate modules for each function
Well-documented code	âœ… Met	Docstrings and comments
Testable code	âœ… Met	Unit test structure
ğŸ“ Learning Outcomes Achieved
âœ… Parse and analyze large files using Python

âœ… Apply regular expressions for pattern matching

âœ… Use Pandas for data aggregation and analysis

âœ… Create visualizations using Matplotlib

âœ… Implement exception handling for real-world data issues

âœ… Apply logging mechanisms for monitoring execution

âœ… Write optimized, readable, testable Python code

âœ… Build web interfaces with Flask

âœ… Follow software engineering best practices

ğŸ”§ Technical Stack
Backend: Python 3.8+, Flask

Data Processing: Pandas, NumPy

Visualization: Matplotlib, Chart.js

Parsing: Regular Expressions (re module)

Logging: Python logging module

Frontend: HTML5, CSS3, JavaScript (ES6+)

Development: Virtual Environments, Git

ğŸ§ª Testing
Run Performance Test
bash
python generate_large_logs.py
Test with Sample Data
bash
cd src
python main.py
Web Interface Test
bash
python app.py
# Visit: http://localhost:5000
# Click "Analyze 50K Sample"
ğŸ“ˆ Performance Optimization
Stream Processing: Line-by-line reading for memory efficiency

Batch Processing: Progress updates during large file analysis

Caching: Results caching for repeated analysis

Asynchronous Operations: Non-blocking web interface

ğŸš€ Deployment
Production Deployment Suggestions
Use Gunicorn for production WSGI server

Configure Nginx as reverse proxy

Set up Redis for session management

Implement authentication for secure access

Configure logging for production monitoring

Docker Deployment (Optional)
dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 5000
CMD ["python", "app.py"]
ğŸ¤ Contributing
Fork the repository

Create a feature branch

Commit your changes

Push to the branch

Open a Pull Request

ğŸ“„ License
This project is licensed under the MIT License - see the LICENSE file for details.
